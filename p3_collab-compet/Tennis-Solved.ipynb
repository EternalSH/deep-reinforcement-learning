{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the third project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Tennis.app\"`\n",
    "- **Windows** (x86): `\"path/to/Tennis_Windows_x86/Tennis.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Tennis_Windows_x86_64/Tennis.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Tennis_Linux/Tennis.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Tennis_Linux/Tennis.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Tennis.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Tennis.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"Tennis_Windows_x86_64/Tennis.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, two agents control rackets to bounce a ball over a net. If an agent hits the ball over the net, it receives a reward of +0.1.  If an agent lets a ball hit the ground or hits the ball out of bounds, it receives a reward of -0.01.  Thus, the goal of each agent is to keep the ball in play.\n",
    "\n",
    "The observation space consists of 8 variables corresponding to the position and velocity of the ball and racket. Two continuous actions are available, corresponding to movement toward (or away from) the net, and jumping. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agents and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agents' performance, if they select actions at random with each time step.  A window should pop up that allows you to observe the agents.\n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agents are able to use their experiences to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import datetime\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from maddpg import Agent\n",
    "\n",
    "NUM_AGENTS = 2\n",
    "\n",
    "def maddpg(n_episodes, max_t, config, window_size=100, print_every=10, early_break=False):\n",
    "    agents = [Agent(config, state_size=state_size, action_size=action_size, random_seed=0) for _ in range(2)]\n",
    "    scores_deque = deque(maxlen=window_size)\n",
    "    scores_short = deque(maxlen=print_every)\n",
    "    all_scores = []\n",
    "    start_time = datetime.datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print('{} Starts training'.format(start_time))\n",
    "    \n",
    "    best = [-np.inf, -np.inf]\n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        \n",
    "        for i in range(NUM_AGENTS):\n",
    "            agents[i].reset()\n",
    "            \n",
    "        env_info = env.reset(train_mode=True)[brain_name]        \n",
    "        states = np.reshape(env_info.vector_observations, (1,48))        \n",
    "        scores = np.zeros(NUM_AGENTS)\n",
    "        sum_ep = np.zeros(2)\n",
    "                    \n",
    "        t = 0\n",
    "        \n",
    "        while True:\n",
    "            t += 1            \n",
    "            \n",
    "            actions = np.concatenate((agents[0].act(states), agents[1].act(states)), axis=0).flatten()\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            \n",
    "            next_states = np.reshape(env_info.vector_observations, (1, 48))\n",
    "            rewards = env_info.rewards\n",
    "            dones = env_info.local_done\n",
    "                        \n",
    "            # Perform agent step\n",
    "            for i in range(NUM_AGENTS):  \n",
    "                agents[i].step(t, states, actions, rewards[i], next_states, dones, i)\n",
    "                sum_ep[i] += rewards[i]\n",
    "                \n",
    "            states = next_states\n",
    "            scores += np.max(rewards)\n",
    "            \n",
    "            if early_break and np.any(dones):\n",
    "                break\n",
    "\n",
    "        for i in range(NUM_AGENTS):\n",
    "            if best[i] < sum_ep[i]:\n",
    "                best[i] = sum_ep[i]\n",
    "                            \n",
    "        max_score = np.max(scores)\n",
    "        scores_deque.append(max_score)\n",
    "        scores_short.append(max_score)\n",
    "        all_scores.append(max_score)            \n",
    "            \n",
    "        if i_episode % print_every == 0:        \n",
    "            current_time = datetime.datetime.now().strftime(\"%H:%M:%S\")\n",
    "            debug_string = '{} Episode {}\\t Episode score: {:.3f}\\tAvg  100: {:.3f} {:.3f}, bests: {:.3f} {:.3f}'.format(current_time, i_episode, max_score, np.mean(scores_deque), np.mean(scores_short), best[0], best[1])\n",
    "            print(debug_string)\n",
    "           \n",
    "        if np.mean(scores_deque)>=0.5:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.3f}'.format(i_episode-100, np.mean(scores_deque)))\n",
    "            \n",
    "            for agent_i in range(2):\n",
    "                torch.save(agents[i].actor_local.state_dict(), 'agent_{}_checkpoint_actor.pth'.format(agent_i))\n",
    "                torch.save(agents[i].critic_local.state_dict(), 'agent_{}_checkpoint_critic.pth'.format(agent_i))\n",
    "            break\n",
    "            \n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "03:37:01 Starts training\n",
      "03:37:03 Episode 10\t Episode score: 0.000\tAvg  100: 0.010 0.010, bests: 0.000 0.090\n",
      "03:37:11 Episode 20\t Episode score: 0.000\tAvg  100: 0.010 0.010, bests: 0.000 0.090\n",
      "03:37:19 Episode 30\t Episode score: 0.000\tAvg  100: 0.010 0.010, bests: 0.000 0.100\n",
      "03:37:31 Episode 40\t Episode score: 0.200\tAvg  100: 0.023 0.060, bests: 0.100 0.100\n",
      "03:37:42 Episode 50\t Episode score: 0.000\tAvg  100: 0.026 0.040, bests: 0.100 0.100\n",
      "03:37:52 Episode 60\t Episode score: 0.100\tAvg  100: 0.027 0.030, bests: 0.100 0.100\n",
      "03:38:01 Episode 70\t Episode score: 0.000\tAvg  100: 0.027 0.030, bests: 0.100 0.100\n",
      "03:38:10 Episode 80\t Episode score: 0.000\tAvg  100: 0.026 0.020, bests: 0.100 0.100\n",
      "03:38:22 Episode 90\t Episode score: 0.100\tAvg  100: 0.030 0.060, bests: 0.100 0.100\n",
      "03:38:33 Episode 100\t Episode score: 0.100\tAvg  100: 0.032 0.050, bests: 0.100 0.100\n",
      "03:38:48 Episode 110\t Episode score: 0.000\tAvg  100: 0.040 0.090, bests: 0.100 0.100\n",
      "03:38:59 Episode 120\t Episode score: 0.200\tAvg  100: 0.044 0.050, bests: 0.100 0.100\n",
      "03:39:11 Episode 130\t Episode score: 0.000\tAvg  100: 0.048 0.050, bests: 0.100 0.190\n",
      "03:39:26 Episode 140\t Episode score: 0.400\tAvg  100: 0.052 0.100, bests: 0.190 0.200\n",
      "03:39:41 Episode 150\t Episode score: 0.000\tAvg  100: 0.057 0.090, bests: 0.190 0.200\n",
      "03:39:53 Episode 160\t Episode score: 0.000\tAvg  100: 0.058 0.040, bests: 0.190 0.200\n",
      "03:40:03 Episode 170\t Episode score: 0.000\tAvg  100: 0.059 0.040, bests: 0.190 0.200\n",
      "03:40:15 Episode 180\t Episode score: 0.100\tAvg  100: 0.063 0.060, bests: 0.190 0.200\n",
      "03:40:28 Episode 190\t Episode score: 0.100\tAvg  100: 0.064 0.070, bests: 0.190 0.200\n",
      "03:40:46 Episode 200\t Episode score: 0.200\tAvg  100: 0.071 0.120, bests: 0.200 0.200\n",
      "03:40:56 Episode 210\t Episode score: 0.100\tAvg  100: 0.067 0.050, bests: 0.200 0.200\n",
      "03:41:11 Episode 220\t Episode score: 0.000\tAvg  100: 0.071 0.090, bests: 0.200 0.200\n",
      "03:41:30 Episode 230\t Episode score: 0.300\tAvg  100: 0.079 0.130, bests: 0.200 0.200\n",
      "03:41:49 Episode 240\t Episode score: 0.400\tAvg  100: 0.083 0.140, bests: 0.200 0.200\n",
      "03:42:06 Episode 250\t Episode score: 0.100\tAvg  100: 0.085 0.110, bests: 0.200 0.200\n",
      "03:42:20 Episode 260\t Episode score: 0.200\tAvg  100: 0.089 0.080, bests: 0.200 0.200\n",
      "03:42:34 Episode 270\t Episode score: 0.100\tAvg  100: 0.093 0.080, bests: 0.200 0.200\n",
      "03:42:52 Episode 280\t Episode score: 0.100\tAvg  100: 0.098 0.110, bests: 0.200 0.200\n",
      "03:43:10 Episode 290\t Episode score: 0.000\tAvg  100: 0.103 0.119, bests: 0.200 0.200\n",
      "03:43:25 Episode 300\t Episode score: 0.200\tAvg  100: 0.100 0.090, bests: 0.200 0.200\n",
      "03:43:44 Episode 310\t Episode score: 0.200\tAvg  100: 0.107 0.120, bests: 0.200 0.300\n",
      "03:43:58 Episode 320\t Episode score: 0.100\tAvg  100: 0.107 0.090, bests: 0.200 0.300\n",
      "03:44:17 Episode 330\t Episode score: 0.200\tAvg  100: 0.107 0.130, bests: 0.200 0.300\n",
      "03:44:38 Episode 340\t Episode score: 0.100\tAvg  100: 0.108 0.150, bests: 0.200 0.300\n",
      "03:44:59 Episode 350\t Episode score: 0.100\tAvg  100: 0.112 0.150, bests: 0.200 0.300\n",
      "03:45:20 Episode 360\t Episode score: 0.100\tAvg  100: 0.119 0.150, bests: 0.200 0.300\n",
      "03:45:35 Episode 370\t Episode score: 0.100\tAvg  100: 0.121 0.100, bests: 0.200 0.300\n",
      "03:45:49 Episode 380\t Episode score: 0.000\tAvg  100: 0.118 0.080, bests: 0.200 0.300\n",
      "03:46:06 Episode 390\t Episode score: 0.100\tAvg  100: 0.117 0.110, bests: 0.200 0.300\n",
      "03:46:25 Episode 400\t Episode score: 0.100\tAvg  100: 0.120 0.120, bests: 0.200 0.300\n",
      "03:46:49 Episode 410\t Episode score: 0.000\tAvg  100: 0.123 0.150, bests: 0.200 0.300\n",
      "03:47:03 Episode 420\t Episode score: 0.200\tAvg  100: 0.122 0.080, bests: 0.200 0.300\n",
      "03:47:18 Episode 430\t Episode score: 0.000\tAvg  100: 0.118 0.090, bests: 0.200 0.300\n",
      "03:47:40 Episode 440\t Episode score: 0.000\tAvg  100: 0.120 0.170, bests: 0.200 0.300\n",
      "03:47:57 Episode 450\t Episode score: 0.100\tAvg  100: 0.115 0.100, bests: 0.200 0.300\n",
      "03:48:18 Episode 460\t Episode score: 0.200\tAvg  100: 0.116 0.160, bests: 0.200 0.300\n",
      "03:48:31 Episode 470\t Episode score: 0.200\tAvg  100: 0.113 0.070, bests: 0.200 0.300\n",
      "03:48:47 Episode 480\t Episode score: 0.200\tAvg  100: 0.114 0.090, bests: 0.200 0.300\n",
      "03:49:16 Episode 490\t Episode score: 0.200\tAvg  100: 0.127 0.240, bests: 0.300 0.300\n",
      "03:49:33 Episode 500\t Episode score: 0.100\tAvg  100: 0.126 0.110, bests: 0.300 0.300\n",
      "03:49:51 Episode 510\t Episode score: 0.100\tAvg  100: 0.123 0.120, bests: 0.300 0.300\n",
      "03:50:09 Episode 520\t Episode score: 0.100\tAvg  100: 0.126 0.110, bests: 0.300 0.300\n",
      "03:50:27 Episode 530\t Episode score: 0.100\tAvg  100: 0.130 0.130, bests: 0.300 0.300\n",
      "03:50:50 Episode 540\t Episode score: 0.100\tAvg  100: 0.131 0.180, bests: 0.390 0.500\n",
      "03:51:20 Episode 550\t Episode score: 0.100\tAvg  100: 0.143 0.220, bests: 0.500 0.500\n",
      "03:51:41 Episode 560\t Episode score: 0.100\tAvg  100: 0.143 0.160, bests: 0.500 0.500\n",
      "03:52:10 Episode 570\t Episode score: 0.300\tAvg  100: 0.160 0.240, bests: 0.500 0.500\n",
      "03:52:33 Episode 580\t Episode score: 0.200\tAvg  100: 0.168 0.170, bests: 0.500 0.500\n",
      "03:52:56 Episode 590\t Episode score: 0.200\tAvg  100: 0.162 0.180, bests: 0.500 0.500\n",
      "03:53:19 Episode 600\t Episode score: 0.200\tAvg  100: 0.169 0.180, bests: 0.500 0.500\n",
      "03:53:42 Episode 610\t Episode score: 0.100\tAvg  100: 0.174 0.170, bests: 0.500 0.500\n",
      "03:54:04 Episode 620\t Episode score: 0.000\tAvg  100: 0.180 0.170, bests: 0.500 0.500\n",
      "03:54:21 Episode 630\t Episode score: 0.100\tAvg  100: 0.179 0.120, bests: 0.500 0.500\n",
      "03:54:43 Episode 640\t Episode score: 0.000\tAvg  100: 0.178 0.170, bests: 0.500 0.500\n",
      "03:55:10 Episode 650\t Episode score: 0.100\tAvg  100: 0.177 0.210, bests: 0.500 0.500\n",
      "03:55:35 Episode 660\t Episode score: 0.600\tAvg  100: 0.181 0.200, bests: 0.500 0.500\n",
      "03:56:01 Episode 670\t Episode score: 0.200\tAvg  100: 0.178 0.210, bests: 0.500 0.500\n",
      "03:56:42 Episode 680\t Episode score: 0.000\tAvg  100: 0.198 0.370, bests: 0.500 0.600\n",
      "03:57:21 Episode 690\t Episode score: 0.300\tAvg  100: 0.216 0.360, bests: 0.590 0.700\n",
      "03:58:07 Episode 700\t Episode score: 0.800\tAvg  100: 0.239 0.410, bests: 0.590 0.700\n",
      "03:59:05 Episode 710\t Episode score: 0.300\tAvg  100: 0.278 0.560, bests: 1.200 1.190\n",
      "03:59:26 Episode 720\t Episode score: 0.100\tAvg  100: 0.277 0.160, bests: 1.200 1.190\n",
      "04:01:04 Episode 730\t Episode score: 0.100\tAvg  100: 0.363 0.980, bests: 2.090 2.200\n",
      "04:01:45 Episode 740\t Episode score: 0.100\tAvg  100: 0.384 0.380, bests: 2.090 2.200\n",
      "04:02:08 Episode 750\t Episode score: 0.400\tAvg  100: 0.381 0.180, bests: 2.090 2.200\n",
      "04:03:20 Episode 760\t Episode score: 1.200\tAvg  100: 0.431 0.700, bests: 2.090 2.200\n",
      "04:04:20 Episode 770\t Episode score: 0.100\tAvg  100: 0.466 0.560, bests: 2.090 2.200\n",
      "\n",
      "Environment solved in 676 episodes!\tAverage Score: 0.510\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'BUFFER_SIZE': int(1e6),        # replay buffer size\n",
    "    'BATCH_SIZE': 128,              # minibatch size\n",
    "    'GAMMA': 0.99,                  # discount factor\n",
    "    'TAU': 7e-2,                    # for soft update of target parameters\n",
    "    'LR_ACTOR': 1e-3,               # learning rate of the actor \n",
    "    'LR_CRITIC': 1e-3,              # learning rate of the critic\n",
    "    'WEIGHT_DECAY': 0,              # L2 weight decay\n",
    "\n",
    "    'DDPG_LEARN_TIMES': 1,\n",
    "    'DDPG_UPDATE_EVERY': 1,\n",
    "\n",
    "    'NOISE_ASYNC': False,\n",
    "    'NOISE_EPSILON_MIN': 4e-4,\n",
    "    'NOISE_EPSILON': 5.5,           # explore/exploit from the noise generator\n",
    "    'NOISE_EPSILON_DECAY': 6e-4,    # decay rate for noise process\n",
    "\n",
    "    'OU_THETA': 0.12,\n",
    "    'OU_SIGMA': 0.2,\n",
    "\n",
    "    'device': torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "}\n",
    "\n",
    "\n",
    "print(f\"Using device: {config['device']}\")\n",
    "scores = maddpg(3000, 2000, config, early_break = True, print_every = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()\n",
    "plt.savefig('result.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
